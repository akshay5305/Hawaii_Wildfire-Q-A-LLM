{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 485,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.020618556701030927,
      "grad_norm": 6.751557350158691,
      "learning_rate": 9.938144329896908e-05,
      "loss": 4.0189,
      "step": 10
    },
    {
      "epoch": 0.041237113402061855,
      "grad_norm": 8.175172805786133,
      "learning_rate": 9.869415807560138e-05,
      "loss": 3.3328,
      "step": 20
    },
    {
      "epoch": 0.061855670103092786,
      "grad_norm": 13.8007230758667,
      "learning_rate": 9.800687285223368e-05,
      "loss": 2.8821,
      "step": 30
    },
    {
      "epoch": 0.08247422680412371,
      "grad_norm": 8.171640396118164,
      "learning_rate": 9.731958762886598e-05,
      "loss": 2.9231,
      "step": 40
    },
    {
      "epoch": 0.10309278350515463,
      "grad_norm": 5.173559665679932,
      "learning_rate": 9.663230240549829e-05,
      "loss": 2.8468,
      "step": 50
    },
    {
      "epoch": 0.12371134020618557,
      "grad_norm": 10.099005699157715,
      "learning_rate": 9.594501718213059e-05,
      "loss": 2.9039,
      "step": 60
    },
    {
      "epoch": 0.14432989690721648,
      "grad_norm": 6.754998683929443,
      "learning_rate": 9.525773195876289e-05,
      "loss": 2.896,
      "step": 70
    },
    {
      "epoch": 0.16494845360824742,
      "grad_norm": 5.00461483001709,
      "learning_rate": 9.457044673539519e-05,
      "loss": 2.4139,
      "step": 80
    },
    {
      "epoch": 0.18556701030927836,
      "grad_norm": 5.596841812133789,
      "learning_rate": 9.388316151202749e-05,
      "loss": 2.6944,
      "step": 90
    },
    {
      "epoch": 0.20618556701030927,
      "grad_norm": 6.639853477478027,
      "learning_rate": 9.31958762886598e-05,
      "loss": 2.4574,
      "step": 100
    },
    {
      "epoch": 0.2268041237113402,
      "grad_norm": 5.0004496574401855,
      "learning_rate": 9.25085910652921e-05,
      "loss": 2.8185,
      "step": 110
    },
    {
      "epoch": 0.24742268041237114,
      "grad_norm": 5.9237189292907715,
      "learning_rate": 9.18213058419244e-05,
      "loss": 2.679,
      "step": 120
    },
    {
      "epoch": 0.26804123711340205,
      "grad_norm": 5.975997447967529,
      "learning_rate": 9.11340206185567e-05,
      "loss": 2.7534,
      "step": 130
    },
    {
      "epoch": 0.28865979381443296,
      "grad_norm": 7.2662529945373535,
      "learning_rate": 9.0446735395189e-05,
      "loss": 2.64,
      "step": 140
    },
    {
      "epoch": 0.30927835051546393,
      "grad_norm": 6.187552452087402,
      "learning_rate": 8.975945017182131e-05,
      "loss": 2.5835,
      "step": 150
    },
    {
      "epoch": 0.32989690721649484,
      "grad_norm": 5.43507719039917,
      "learning_rate": 8.907216494845362e-05,
      "loss": 2.3708,
      "step": 160
    },
    {
      "epoch": 0.35051546391752575,
      "grad_norm": 4.362546443939209,
      "learning_rate": 8.838487972508591e-05,
      "loss": 2.5438,
      "step": 170
    },
    {
      "epoch": 0.3711340206185567,
      "grad_norm": 4.398411273956299,
      "learning_rate": 8.769759450171821e-05,
      "loss": 2.5507,
      "step": 180
    },
    {
      "epoch": 0.3917525773195876,
      "grad_norm": 6.081744194030762,
      "learning_rate": 8.701030927835052e-05,
      "loss": 2.2762,
      "step": 190
    },
    {
      "epoch": 0.41237113402061853,
      "grad_norm": 5.881648540496826,
      "learning_rate": 8.632302405498283e-05,
      "loss": 2.5367,
      "step": 200
    },
    {
      "epoch": 0.4329896907216495,
      "grad_norm": 4.951355934143066,
      "learning_rate": 8.563573883161513e-05,
      "loss": 2.5161,
      "step": 210
    },
    {
      "epoch": 0.4536082474226804,
      "grad_norm": 4.314056873321533,
      "learning_rate": 8.494845360824743e-05,
      "loss": 2.5081,
      "step": 220
    },
    {
      "epoch": 0.4742268041237113,
      "grad_norm": 4.431379795074463,
      "learning_rate": 8.426116838487973e-05,
      "loss": 2.5367,
      "step": 230
    },
    {
      "epoch": 0.4948453608247423,
      "grad_norm": 5.175920486450195,
      "learning_rate": 8.357388316151203e-05,
      "loss": 2.5807,
      "step": 240
    },
    {
      "epoch": 0.5154639175257731,
      "grad_norm": 6.56575870513916,
      "learning_rate": 8.288659793814434e-05,
      "loss": 2.2484,
      "step": 250
    },
    {
      "epoch": 0.5360824742268041,
      "grad_norm": 6.0302605628967285,
      "learning_rate": 8.219931271477663e-05,
      "loss": 2.5881,
      "step": 260
    },
    {
      "epoch": 0.5567010309278351,
      "grad_norm": 5.2963948249816895,
      "learning_rate": 8.151202749140893e-05,
      "loss": 2.3749,
      "step": 270
    },
    {
      "epoch": 0.5773195876288659,
      "grad_norm": 4.64434289932251,
      "learning_rate": 8.082474226804125e-05,
      "loss": 2.4326,
      "step": 280
    },
    {
      "epoch": 0.5979381443298969,
      "grad_norm": 5.518579959869385,
      "learning_rate": 8.013745704467355e-05,
      "loss": 2.372,
      "step": 290
    },
    {
      "epoch": 0.6185567010309279,
      "grad_norm": 3.749814748764038,
      "learning_rate": 7.945017182130585e-05,
      "loss": 2.402,
      "step": 300
    },
    {
      "epoch": 0.6391752577319587,
      "grad_norm": 3.6457698345184326,
      "learning_rate": 7.876288659793815e-05,
      "loss": 2.2538,
      "step": 310
    },
    {
      "epoch": 0.6597938144329897,
      "grad_norm": 5.207114219665527,
      "learning_rate": 7.807560137457045e-05,
      "loss": 2.5134,
      "step": 320
    },
    {
      "epoch": 0.6804123711340206,
      "grad_norm": 6.082962512969971,
      "learning_rate": 7.738831615120275e-05,
      "loss": 2.4929,
      "step": 330
    },
    {
      "epoch": 0.7010309278350515,
      "grad_norm": 5.324494361877441,
      "learning_rate": 7.670103092783506e-05,
      "loss": 2.3615,
      "step": 340
    },
    {
      "epoch": 0.7216494845360825,
      "grad_norm": 6.346109867095947,
      "learning_rate": 7.601374570446735e-05,
      "loss": 2.5137,
      "step": 350
    },
    {
      "epoch": 0.7422680412371134,
      "grad_norm": 4.682963848114014,
      "learning_rate": 7.532646048109965e-05,
      "loss": 2.3406,
      "step": 360
    },
    {
      "epoch": 0.7628865979381443,
      "grad_norm": 6.751570701599121,
      "learning_rate": 7.463917525773197e-05,
      "loss": 2.6347,
      "step": 370
    },
    {
      "epoch": 0.7835051546391752,
      "grad_norm": 6.632621765136719,
      "learning_rate": 7.395189003436427e-05,
      "loss": 2.4479,
      "step": 380
    },
    {
      "epoch": 0.8041237113402062,
      "grad_norm": 5.316795349121094,
      "learning_rate": 7.326460481099657e-05,
      "loss": 2.4615,
      "step": 390
    },
    {
      "epoch": 0.8247422680412371,
      "grad_norm": 5.599184513092041,
      "learning_rate": 7.257731958762887e-05,
      "loss": 2.4278,
      "step": 400
    },
    {
      "epoch": 0.845360824742268,
      "grad_norm": 3.965745210647583,
      "learning_rate": 7.189003436426117e-05,
      "loss": 2.2475,
      "step": 410
    },
    {
      "epoch": 0.865979381443299,
      "grad_norm": 6.588029861450195,
      "learning_rate": 7.120274914089347e-05,
      "loss": 2.5058,
      "step": 420
    },
    {
      "epoch": 0.8865979381443299,
      "grad_norm": 5.160254001617432,
      "learning_rate": 7.051546391752579e-05,
      "loss": 2.4979,
      "step": 430
    },
    {
      "epoch": 0.9072164948453608,
      "grad_norm": 3.8330681324005127,
      "learning_rate": 6.982817869415807e-05,
      "loss": 2.2574,
      "step": 440
    },
    {
      "epoch": 0.9278350515463918,
      "grad_norm": 4.326326370239258,
      "learning_rate": 6.914089347079037e-05,
      "loss": 2.2982,
      "step": 450
    },
    {
      "epoch": 0.9484536082474226,
      "grad_norm": 5.028839588165283,
      "learning_rate": 6.845360824742269e-05,
      "loss": 2.4893,
      "step": 460
    },
    {
      "epoch": 0.9690721649484536,
      "grad_norm": 4.526697158813477,
      "learning_rate": 6.776632302405499e-05,
      "loss": 2.6755,
      "step": 470
    },
    {
      "epoch": 0.9896907216494846,
      "grad_norm": 5.48358154296875,
      "learning_rate": 6.707903780068729e-05,
      "loss": 2.2855,
      "step": 480
    }
  ],
  "logging_steps": 10,
  "max_steps": 1455,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2113257385451520.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
